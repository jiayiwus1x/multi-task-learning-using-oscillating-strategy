{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A multi-layer perceptron for binary classification of MNIST handwritten digits.'''\n",
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "from autograd import grad\n",
    "from autograd.misc.flatten import flatten\n",
    "from data import load_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la\n",
    "\n",
    "'''Neural net functions. Simple fully connected neural network with sigmoid binary cross-entropy loss'''\n",
    "\n",
    "def init_random_params(scale, layer_sizes, rs=npr.RandomState(0)):\n",
    "    '''Build a list of (weights, biases) tuples,\n",
    "       one for each layer in the net.'''\n",
    "    return [(scale * rs.randn(m, n),   # weight matrix\n",
    "             scale * rs.randn(n))      # bias vector\n",
    "            for m, n in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def neural_net_predict(params, inputs):\n",
    "    '''Implements a deep neural network for classification.\n",
    "       params is a list of (weights, bias) tuples.\n",
    "       inputs is an (N x D) matrix.\n",
    "       returns normalized class log-probabilities.'''\n",
    "    for W, b in params:\n",
    "        outputs = np.dot(inputs, W) + b\n",
    "        inputs = np.tanh(outputs)\n",
    "    return sigmoid(outputs)\n",
    "\n",
    "def cross_entropy(params, inputs, targets):\n",
    "    '''Cross entropy loss function. Measure difference \n",
    "       between probabilistic ouput and label'''\n",
    "    m = inputs.shape[0]\n",
    "    predict = neural_net_predict(params, inputs)\n",
    "    return (1/m)*np.sum(-targets*np.log(predict)-(1-targets)*np.log(1-predict))\n",
    "\n",
    "def accuracy(params, inputs, targets):\n",
    "    '''Computes the accuracy of my neural network predictions'''\n",
    "    predict_probability = neural_net_predict(params, inputs)\n",
    "    predict = predict_probability > 0.5\n",
    "    return np.mean(predict == targets)\n",
    "\n",
    "def batch_indices(iter):\n",
    "    '''batches the data to use for stochastic optimization'''\n",
    "    idx = iter % num_batches\n",
    "    return slice(idx * batch_size, (idx+1) * batch_size)\n",
    "\n",
    "# Define training objective\n",
    "def objective(params, iter, train_labels):\n",
    "    '''evaluating the cross entropy loss on the batch. batch objective function.'''\n",
    "    idx = batch_indices(iter)\n",
    "    return cross_entropy(params, train_images[idx], train_labels[idx])\n",
    "\n",
    "def record_accuracy(params, iter, train_labels, test_labels):\n",
    "    '''output training error and testing error'''\n",
    "    train_acc  = accuracy(params, train_images, train_labels)\n",
    "    test_acc  = accuracy(params, test_images, test_labels)\n",
    "    return train_acc, test_acc \n",
    "\n",
    "def adam(grad, x, train_lab, test_lab, callback=None, num_iters=100,\n",
    "         step_size=0.001, b1=0.9, b2=0.999, eps=10**-8):\n",
    "    \n",
    "    '''Adam as described in http://arxiv.org/pdf/1412.6980.pdf.\n",
    "    It's basically RMSprop with momentum and some correction terms.'''\n",
    "    \n",
    "    x_flat,unflatten = flatten(x)\n",
    "    m = np.zeros(len(x_flat))\n",
    "    v = np.zeros(len(x_flat))\n",
    "    \n",
    "    train_perf = [0]\n",
    "    test_perf = [0]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        if test_perf[-1] > 0.98:\n",
    "            break\n",
    "        \n",
    "        g = flatten(grad(x, i, train_lab))[0]\n",
    "        x_flat = flatten(x)[0]\n",
    "        \n",
    "        if callback: \n",
    "            train_acc, test_acc = callback(x, i, train_lab, test_lab)\n",
    "            train_perf.append(train_acc)\n",
    "            test_perf.append(test_acc)\n",
    "            \n",
    "        m = (1 - b1) * g      + b1 * m  # First  moment estimate.\n",
    "        v = (1 - b2) * (g**2) + b2 * v  # Second moment estimate.\n",
    "        mhat = m / (1 - b1**(i + 1))    # Bias correction.\n",
    "        vhat = v / (1 - b2**(i + 1))\n",
    "        x = unflatten(x_flat - step_size*mhat/(np.sqrt(vhat) + eps))\n",
    "    return x, i, train_perf, test_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data and set experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading training data\n",
      "batch size per iteration is 256\n",
      "number of batches per epoch is 235\n",
      "number of epochs is 10\n",
      "max iterations per goal is 2350\n"
     ]
    }
   ],
   "source": [
    "N, train_images, train_labels_orig, test_images, test_labels_orig = load_mnist() # download and load data\n",
    "print(\"done loading training data\")\n",
    "\n",
    "# Define the layers of your neural network\n",
    "layer_sizes = [784,10,5,1]\n",
    "\n",
    "# Training parameters\n",
    "param_scale = 0.1 #scale of initial parameters(weight matrix and bias vector)\n",
    "batch_size = 256 \n",
    "num_epochs = 10\n",
    "step_size = 0.001\n",
    "num_batches = int(np.ceil(len(train_images) / batch_size))\n",
    "max_iter = num_epochs * num_batches\n",
    "\n",
    "print('batch size per iteration is', batch_size)\n",
    "print('number of batches per epoch is', num_batches)\n",
    "print('number of epochs is', num_epochs)\n",
    "print('max iterations per goal is', max_iter)\n",
    "\n",
    "# set goals\n",
    "goal1 = 4\n",
    "goal2 = 5\n",
    "\n",
    "# Get gradient of objective using autograd.\n",
    "objective_grad = grad(objective)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oscillation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_osc_goal(train_labels_orig, test_labels_orig, goal1, goal2, init_params, obj_grad, step_size, max_it):\n",
    "\n",
    "    train_n = int(train_labels_orig.shape[0])\n",
    "    test_n = int(test_labels_orig.shape[0])\n",
    "\n",
    "    ### goal 1 ###\n",
    "    train_labels = train_labels_orig[:,goal1].reshape((train_n,1))\n",
    "    test_labels = test_labels_orig[:,goal1].reshape((test_n,1))\n",
    "\n",
    "    print('')\n",
    "    print('no oscillation experiment begin')\n",
    "    print('training goal 1')\n",
    "    opt_params_g1, iter_g1, tr_perf_g1, tst_perf_g1 = adam(obj_grad, init_params, train_labels, test_labels,\n",
    "                            step_size=step_size,num_iters=max_it, callback=record_accuracy)\n",
    "    \n",
    "    print('goal 1 converged')\n",
    "    print('training accuracy for goal 2 optimal =', tst_perf_g1[-1])\n",
    "    plt.plot(tst_perf_g1, label = 'goal 1')\n",
    "    \n",
    "    ### goal 2 ###\n",
    "    train_labels = train_labels_orig[:,goal2].reshape((train_n,1))\n",
    "    test_labels = test_labels_orig[:,goal2].reshape((test_n,1))\n",
    "\n",
    "    print('training goal 2')\n",
    "    opt_params_g2, iter_g2, tr_perf_g2, tst_perf_g2 = adam(obj_grad, init_params, train_labels, test_labels,\n",
    "                            step_size=step_size,num_iters=max_it, callback=record_accuracy)\n",
    "    print('goal 2 converged')\n",
    "    print('training accuracy for goal 2 optimal =', tst_perf_g2[-1])\n",
    "    plt.plot(tst_perf_g2, label = 'goal 2')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('probablity of recognizing the hand digit correctly')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    l2_diff = la.norm(flatten(opt_params_g1)[0]-flatten(opt_params_g2)[0],2)\n",
    "    \n",
    "    return l2_diff,iter_g1,iter_g2\n",
    "\n",
    "def osc_goal(train_labels_orig, test_labels_orig, goal1, goal2, init_params, obj_grad, step_size, max_it, num_cycles):\n",
    "\n",
    "    train_n = int(train_labels_orig.shape[0])\n",
    "    test_n = int(test_labels_orig.shape[0])\n",
    "\n",
    "    train_labels_g1 = train_labels_orig[:,goal1].reshape((train_n,1))\n",
    "    test_labels_g1 = test_labels_orig[:,goal1].reshape((test_n,1))\n",
    "    \n",
    "    train_labels_g2 = train_labels_orig[:,goal2].reshape((train_n,1))\n",
    "    test_labels_g2 = test_labels_orig[:,goal2].reshape((test_n,1))\n",
    "    \n",
    "    print('')\n",
    "    print('oscillating goals experiment begin')\n",
    "    print('initial optimization')\n",
    "    print('training goal 1')\n",
    "    opt_params_g1, iter_g1, _, tst_perf_g1 = adam(obj_grad, init_params, train_labels_g1, test_labels_g1,\n",
    "                            step_size=step_size,num_iters=max_it, callback=record_accuracy)\n",
    "    \n",
    "    print('goal 1 converged')\n",
    "    print('training accuracy for goal 2 optimal =', tst_perf_g1[-1])\n",
    "    \n",
    "    cycle_counter = 0\n",
    "    \n",
    "    l2_list = []\n",
    "    iter_g1g2 = []\n",
    "    iter_g2g1 = []\n",
    "    \n",
    "    while cycle_counter < num_cycles:\n",
    "\n",
    "        print('')\n",
    "        print('cycle', cycle_counter+1)\n",
    "\n",
    "        print('training goal 2')\n",
    "        opt_params_g2, iter_g2, _, tst_perf_g2 = adam(obj_grad, opt_params_g1, train_labels_g2, test_labels_g2,\n",
    "                                step_size=step_size,num_iters=max_it, callback=record_accuracy)\n",
    "        print('goal 2 converged')\n",
    "        print('training accuracy for goal 2 optimal =', tst_perf_g2[-1])\n",
    "\n",
    "        \n",
    "        print('training goal 1')\n",
    "        opt_params_g1, iter_g1, _, tst_perf_g1 = adam(obj_grad, opt_params_g2, train_labels_g1, test_labels_g1,\n",
    "                                step_size=step_size,num_iters=max_it, callback=record_accuracy)\n",
    "\n",
    "        print('goal 1 converged')\n",
    "        print('training accuracy for goal 2 optimal =', tst_perf_g1[-1])\n",
    "        \n",
    "        iter_g1g2.append(iter_g2)\n",
    "        iter_g2g1.append(iter_g1)\n",
    "        l2_list.append(la.norm(flatten(opt_params_g1)[0]-flatten(opt_params_g2)[0],2))\n",
    "\n",
    "        cycle_counter += 1\n",
    "        \n",
    "    return l2_list,iter_g1g2,iter_g2g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "no oscillation experiment begin\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9801\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9802\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time using 65.18331098556519\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_params = init_random_params(param_scale, layer_sizes)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "l2_no_osc, g1_iter, g2_iter = no_osc_goal(train_labels_orig, test_labels_orig, \n",
    "                                 goal1, goal2, init_params, objective_grad, step_size, max_iter)\n",
    "end = time.time()\n",
    "print('time using', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance for not oscillating goal: 9.020879238985339\n"
     ]
    }
   ],
   "source": [
    "print('L2 distance for not oscillating goal:', l2_no_osc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oscillating goals experiment begin\n",
      "initial optimization\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9805\n",
      "\n",
      "cycle 1\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9803\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9803\n",
      "\n",
      "cycle 2\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9802\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9803\n",
      "\n",
      "cycle 3\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9801\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9804\n",
      "\n",
      "cycle 4\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9801\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9801\n",
      "\n",
      "cycle 5\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9802\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9802\n",
      "\n",
      "cycle 6\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9802\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9803\n",
      "\n",
      "cycle 7\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9801\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9803\n",
      "\n",
      "cycle 8\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9804\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9802\n",
      "\n",
      "cycle 9\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9801\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9803\n",
      "\n",
      "cycle 10\n",
      "training goal 2\n",
      "goal 2 converged\n",
      "training accuracy for goal 2 optimal = 0.9801\n",
      "training goal 1\n",
      "goal 1 converged\n",
      "training accuracy for goal 2 optimal = 0.9802\n",
      "173.7672221660614\n"
     ]
    }
   ],
   "source": [
    "num_cycles = 10\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "l2_osc, g1g2_iter, g2g1_iter = osc_goal(train_labels_orig, test_labels_orig, \n",
    "                                        goal1, goal2, init_params, objective_grad, step_size, max_iter, num_cycles)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance for not oscillating goal: 9.020879238985339\n",
      "L2 distance for oscillating goals: 1.5766060142149836\n"
     ]
    }
   ],
   "source": [
    "print('L2 distance for not oscillating goal:', l2_no_osc)\n",
    "print('L2 distance for oscillating goals:', l2_osc[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
